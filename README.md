# Chatbot Using meta-llama/Meta-Llama-3-70B-Instruct.
# Run on Akash Network
- Here is the [model](https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct) used.
- Docker installed on your local machine( In this case we do not need docker installed as we already have a docker image).
- Akash CLI installed and configured.
- A Hugging Face account with acces to the Meta/llama models
- A Hugging Face (HF) token with read access
- Use the SDL From [here]()
- Replace `hf_your_token` with your Hugging Face token in the SDL
- Click deploy button
- Approve the transaction
- Wait for a while for the model to download
- Check the logs for any updates
- After the model is downloaded use the api code for calling and sending the requests.
- Use Any API testing tools to interact and chat with the model

# Deployment of the Model on Akash Netwoork
